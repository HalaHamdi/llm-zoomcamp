{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e9e1bc29-2b00-43d5-8d01-dca47cf01553",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from rouge import Rouge\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b31860d6-be68-410e-89da-f3f8d755d368",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/results-gpt4o-mini.csv\")\n",
    "# using the first 300 documents\n",
    "df = df.iloc[:300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a523e4f-4036-4b2e-8d28-86bed477cd7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>answer_llm</th>\n",
       "      <th>answer_orig</th>\n",
       "      <th>document</th>\n",
       "      <th>question</th>\n",
       "      <th>course</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>You can sign up for the course by visiting the...</td>\n",
       "      <td>Machine Learning Zoomcamp FAQ\\nThe purpose of ...</td>\n",
       "      <td>0227b872</td>\n",
       "      <td>Where can I sign up for the course?</td>\n",
       "      <td>machine-learning-zoomcamp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>You can sign up using the link provided in the...</td>\n",
       "      <td>Machine Learning Zoomcamp FAQ\\nThe purpose of ...</td>\n",
       "      <td>0227b872</td>\n",
       "      <td>Can you provide a link to sign up?</td>\n",
       "      <td>machine-learning-zoomcamp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Yes, there is an FAQ for the Machine Learning ...</td>\n",
       "      <td>Machine Learning Zoomcamp FAQ\\nThe purpose of ...</td>\n",
       "      <td>0227b872</td>\n",
       "      <td>Is there an FAQ for this Machine Learning course?</td>\n",
       "      <td>machine-learning-zoomcamp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The context does not provide any specific info...</td>\n",
       "      <td>Machine Learning Zoomcamp FAQ\\nThe purpose of ...</td>\n",
       "      <td>0227b872</td>\n",
       "      <td>Does this course have a GitHub repository for ...</td>\n",
       "      <td>machine-learning-zoomcamp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>To structure your questions and answers for th...</td>\n",
       "      <td>Machine Learning Zoomcamp FAQ\\nThe purpose of ...</td>\n",
       "      <td>0227b872</td>\n",
       "      <td>How can I structure my questions and answers f...</td>\n",
       "      <td>machine-learning-zoomcamp</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          answer_llm  \\\n",
       "0  You can sign up for the course by visiting the...   \n",
       "1  You can sign up using the link provided in the...   \n",
       "2  Yes, there is an FAQ for the Machine Learning ...   \n",
       "3  The context does not provide any specific info...   \n",
       "4  To structure your questions and answers for th...   \n",
       "\n",
       "                                         answer_orig  document  \\\n",
       "0  Machine Learning Zoomcamp FAQ\\nThe purpose of ...  0227b872   \n",
       "1  Machine Learning Zoomcamp FAQ\\nThe purpose of ...  0227b872   \n",
       "2  Machine Learning Zoomcamp FAQ\\nThe purpose of ...  0227b872   \n",
       "3  Machine Learning Zoomcamp FAQ\\nThe purpose of ...  0227b872   \n",
       "4  Machine Learning Zoomcamp FAQ\\nThe purpose of ...  0227b872   \n",
       "\n",
       "                                            question  \\\n",
       "0                Where can I sign up for the course?   \n",
       "1                 Can you provide a link to sign up?   \n",
       "2  Is there an FAQ for this Machine Learning course?   \n",
       "3  Does this course have a GitHub repository for ...   \n",
       "4  How can I structure my questions and answers f...   \n",
       "\n",
       "                      course  \n",
       "0  machine-learning-zoomcamp  \n",
       "1  machine-learning-zoomcamp  \n",
       "2  machine-learning-zoomcamp  \n",
       "3  machine-learning-zoomcamp  \n",
       "4  machine-learning-zoomcamp  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83637631-d247-4c91-a508-10c48a016894",
   "metadata": {},
   "source": [
    "## Q1: What's the first value of the resulting vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ec62164-bf10-4038-893b-1964e7bbce82",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You try to use a model that was created with version 3.0.0.dev0, however, your version is 2.7.0. This might cause unexpected behavior or errors. In that case, try to update to the latest version.\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# get the embedding model\n",
    "model_name = \"multi-qa-mpnet-base-dot-v1\"\n",
    "embedding_model = SentenceTransformer(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4cf2d0e8-2db9-4082-81c1-e1ddba9f05f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.42244655"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the embeddings for the first LLM answer\n",
    "answer_llm = df.iloc[0].answer_llm\n",
    "vector = embedding_model.encode(answer_llm)\n",
    "vector[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "966b885d-75a6-47c0-9814-7a6459c7e4b3",
   "metadata": {},
   "source": [
    "## Q2: What's the 75% percentile of the score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "930fdf62-8af5-4812-bcb4-bb1149973150",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "300it [02:19,  2.14it/s]\n"
     ]
    }
   ],
   "source": [
    "evaluations = []\n",
    "\n",
    "for idx,row in tqdm(df.iterrows()):\n",
    "    llm_vector = embedding_model.encode(row[\"answer_llm\"])\n",
    "    orig_vector = embedding_model.encode(row['answer_orig'])\n",
    "    evaluations.append(llm_vector.dot(orig_vector))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2430314c-4b55-4917-a51d-21db1545955a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    300.000000\n",
       "mean      27.495996\n",
       "std        6.384742\n",
       "min        4.547924\n",
       "25%       24.307844\n",
       "50%       28.336870\n",
       "75%       31.674309\n",
       "max       39.476013\n",
       "Name: evaluations, dtype: float64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"evaluations\"]= evaluations\n",
    "df[\"evaluations\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acfd0118-b32f-4d10-abc6-3b20a737ff3a",
   "metadata": {},
   "source": [
    "## Q3: Normalize the embeddings, What's the 75% cosine in the scores?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a4abed3b-c6d9-499f-a067-284163c9aad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(vector):\n",
    "    norm = np.sqrt((vector*vector).sum())\n",
    "    return vector /norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "87712bbc-0eee-44f1-adef-9d3aed511f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn into dict to see if it is faster than df \n",
    "data_dict=df.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f9ba11e8-c6ad-44a8-a5ea-85e6574868c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████| 300/300 [02:20<00:00,  2.14it/s]\n"
     ]
    }
   ],
   "source": [
    "evaluations_norm = []\n",
    "\n",
    "for record in tqdm(data_dict):\n",
    "    llm_vector = embedding_model.encode(record[\"answer_llm\"])\n",
    "    orig_vector = embedding_model.encode(record['answer_orig'])\n",
    "    llm_norm=normalize(llm_vector)\n",
    "    orig_norm=normalize(orig_vector)\n",
    "    evaluations_norm.append(llm_norm.dot(orig_norm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4986be45-7adc-41f4-a42b-41f8e8ea7d19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    300.000000\n",
       "mean       0.728393\n",
       "std        0.157755\n",
       "min        0.125357\n",
       "25%        0.651273\n",
       "50%        0.763761\n",
       "75%        0.836235\n",
       "max        0.958796\n",
       "Name: evaluations_norm, dtype: float64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"evaluations_norm\"]= evaluations_norm\n",
    "df[\"evaluations_norm\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2efb2858-81f8-4616-9b8a-03447cba754d",
   "metadata": {},
   "source": [
    "## Q4. What's the F score for rouge-1\n",
    "\n",
    "ROUGE:\n",
    "- This is a set of metrics that compares two answers based on the overlap of n-grams, word sequences, and word pairs.\n",
    "- It can give a more nuanced view of text similarity than just cosine similarity alone.\n",
    "- There are three scores: rouge-1, rouge-2 and rouge-l, and precision, recall and F1 score for each.\n",
    "- rouge-1 - the overlap of unigrams,\n",
    "- rouge-2 - bigrams,\n",
    "- rouge-l - the longest common subsequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8a95c98b-345c-4a6d-bc64-b563639e23df",
   "metadata": {},
   "outputs": [],
   "source": [
    "rouge_scorer = Rouge()\n",
    "scores = rouge_scorer.get_scores(df['answer_llm'].iloc[10], df['answer_orig'].iloc[10])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4f84f1ef-14dc-48b6-b484-26c02b51417a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge-1': {'r': 0.45454545454545453,\n",
       "  'p': 0.45454545454545453,\n",
       "  'f': 0.45454544954545456},\n",
       " 'rouge-2': {'r': 0.21621621621621623,\n",
       "  'p': 0.21621621621621623,\n",
       "  'f': 0.21621621121621637},\n",
       " 'rouge-l': {'r': 0.3939393939393939,\n",
       "  'p': 0.3939393939393939,\n",
       "  'f': 0.393939388939394}}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71500a85-f8dc-46c4-92bb-b00ac553aa34",
   "metadata": {},
   "source": [
    "## Q5: compute the average between rouge-1, rouge-2 and rouge-l for the same record from Q4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "99cc2c35-40a9-4fa0-b0cb-0afb3bcf9191",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the averages dictionary with zeros\n",
    "averages = {val: 0 for key in scores for val in scores[key]}\n",
    "\n",
    "# Calculate the averages\n",
    "for key in scores:\n",
    "    for val in scores[key]:\n",
    "        averages[val] += scores[key][val]\n",
    "\n",
    "# If you need to calculate the average, make sure to divide by the number of scores\n",
    "# Assuming scores is a nested dictionary and you want the average for each 'val'\n",
    "for val in averages:\n",
    "    count = sum(1 for key in scores if val in scores[key])\n",
    "    averages[val] /= count if count != 0 else 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2a1b94c2-3625-4065-9662-ac47fbbe4894",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'r': 0.35490035490035493, 'p': 0.35490035490035493, 'f': 0.35490034990035496}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "averages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbbaa350-1f60-4638-963a-db0d8176e458",
   "metadata": {},
   "source": [
    "## Q6: What's the aggerage rouge_2 across all the records?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ee569831-ec1a-4c8c-888e-95e3f0ebfa49",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 300/300 [00:00<00:00, 348.00it/s]\n"
     ]
    }
   ],
   "source": [
    "rouge_1 = []\n",
    "rouge_2 = []\n",
    "rouge_l = []\n",
    "for record in tqdm(data_dict):\n",
    "    scores = rouge_scorer.get_scores(record['answer_llm'], record['answer_orig'])[0]\n",
    "    rouge_1.append(scores['rouge-1']['f'])\n",
    "    rouge_2.append(scores['rouge-2']['f'])\n",
    "    rouge_l.append(scores['rouge-l']['f'])\n",
    "    # rouge_avg = (rouge_1 + rouge_2 + rouge_l) / 3  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0fb2c2b6-eee7-493f-8d3c-0c6774be15a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20696501983423318"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"rouge_1_f\"]=rouge_1\n",
    "df[\"rouge_2_f\"]=rouge_2\n",
    "df[\"rouge_l_f\"]=rouge_l\n",
    "\n",
    "df[\"rouge_2_f\"].mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
