{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70de3059-b85e-42fb-ba6e-480ff3bcf864",
   "metadata": {},
   "source": [
    "# Monitoring\n",
    "### In this module we will discuss monitoring which differs than evaluation module.\n",
    "### In this module, we evluate the entire RAG pipeline to ensure that the system works as we expect.\n",
    "### In the evaluation module, we tested only that the Retrival part is working good.\n",
    "\n",
    "## In this module we mainly conisder offline monitoring which means before production."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3cef805-52c9-4234-a990-281422c1e57e",
   "metadata": {},
   "source": [
    "## Load documents with IDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0047f703-523f-4d92-97cf-f91cf54a2de0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/python/3.10.13/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from openai import OpenAI\n",
    "from elasticsearch import Elasticsearch\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba1be445-f7f6-47a4-9b2f-36e0861e7cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the documents. remeber this was the initial dataset we have that\n",
    "# has all the \"answers\" that we used to generate 5 Qs per answer to have \n",
    "# the ground truth dataset that we evaluate upon\n",
    "base_url = 'https://github.com/DataTalksClub/llm-zoomcamp/blob/main'\n",
    "relative_url = '03-vector-search/eval/documents-with-ids.json'\n",
    "docs_url = f'{base_url}/{relative_url}?raw=1'\n",
    "docs_response = requests.get(docs_url)\n",
    "documents = docs_response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6b8d9ef-778d-46e6-9cb8-a1233c975980",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'It depends on your background and previous experience with modules. It is expected to require about 5 - 15 hours per week. [source1] [source2]\\nYou can also calculate it yourself using this data and then update this answer.',\n",
       " 'section': 'General course-related questions',\n",
       " 'question': 'Course - \\u200b\\u200bHow many hours per week am I expected to spend on this  course?',\n",
       " 'course': 'data-engineering-zoomcamp',\n",
       " 'id': 'ea739c65'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c79364-79fe-4bfd-a3dc-f36e7b3ae481",
   "metadata": {},
   "source": [
    "## Load ground truth dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9387ff50-4ca8-4559-bf3d-a789dba01e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = 'https://github.com/DataTalksClub/llm-zoomcamp/blob/main'\n",
    "relative_url = '03-vector-search/eval/ground-truth-data.csv'\n",
    "ground_truth_url = f'{base_url}/{relative_url}?raw=1'\n",
    "\n",
    "df_ground_truth = pd.read_csv(ground_truth_url)\n",
    "df_ground_truth = df_ground_truth[df_ground_truth.course == 'machine-learning-zoomcamp']\n",
    "ground_truth = df_ground_truth.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "821445a9-115a-4a53-b351-e9a6c899fd2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'Are sessions recorded if I miss one?',\n",
       " 'course': 'machine-learning-zoomcamp',\n",
       " 'document': '5170565b'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ground_truth[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "917155d8-a421-4570-ba4a-9f3daab4a3f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Everything is recorded, so you won’t miss anything. You will be able to ask your questions for office hours in advance and we will cover them during the live stream. Also, you can always ask questions in Slack.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for the documents data (not the ground truth) we are generating a dic\n",
    "# id:doc\n",
    "doc_idx= {doc['id']: doc for doc in documents}\n",
    "doc_idx['5170565b']['text'] # the answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d73e37f1-ace1-4d0d-a4d1-688c23073a5c",
   "metadata": {},
   "source": [
    "## Index the data\n",
    "\n",
    "Run this command in your terminal to set up elastic search in docker to help us connect to elastic search locally:\n",
    "\n",
    "docker run -it \\\n",
    "  --rm \\\n",
    "  --name elasticsearch \\\n",
    "  -p 9200:9200 \\\n",
    "  -p 9300:9300 \\\n",
    "  -e \"discovery.type=single-node\" \\\n",
    "  -e \"xpack.security.enabled=false\" \\\n",
    "  docker.elastic.co/elasticsearch/elasticsearch:8.4.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ded215f9-62ba-423d-acc4-07611fe8bf0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initalize the embedding model\n",
    "model_name ='multi-qa-MiniLM-L6-cos-v1'\n",
    "model = SentenceTransformer(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1cc34de7-9a7f-4f73-b62d-c8624e16821a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initalize the vector DB\n",
    "es_client= Elasticsearch('http://localhost:9200')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ea838e89-a4bd-4573-b206-dc933a51c787",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the mapping\n",
    "index_settings= {\n",
    "    \"settings\":{\n",
    "        \"number_of_shards\":1,\n",
    "        \"number_of_replicas\":0\n",
    "    },\n",
    "    \"mappings\":{\n",
    "        \"properties\":{\n",
    "            \"text\":{\"type\":\"text\"},\n",
    "            \"section\":{\"type\":\"text\"},\n",
    "            \"question\":{\"type\":\"text\"},\n",
    "            \"course\":{\"type\":\"keyword\"},\n",
    "            \"id\":{\"type\":\"keyword\"},\n",
    "            \"question_text_vector\":{\"type\":\"dense_vector\",\n",
    "                          \"dims\":384,\n",
    "                          \"index\":True,\n",
    "                          \"similarity\":\"cosine\"},\n",
    "        }\n",
    "    }  \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9c4b338e-9971-4299-8955-f31b1e0a2e2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'acknowledged': True, 'shards_acknowledged': True, 'index': 'course-questions'})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create the index after we have created the mapping \n",
    "index_name = \"course-questions\"\n",
    "es_client.indices.delete(index = index_name , ignore_unavailable=True) # delete index if it exists  \n",
    "es_client.indices.create(index = index_name , body= index_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "10cfdd53-3d17-44da-b558-5977ffb29705",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 948/948 [01:16<00:00, 12.31it/s]\n"
     ]
    }
   ],
   "source": [
    "# create embeddings for the data & put it in the db\n",
    "for doc in tqdm(documents):\n",
    "    question_text= doc['question'] +' '+doc['text']\n",
    "    doc['question_text_vector']= model.encode(question_text)\n",
    "    es_client.index(index= index_name, document=doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47eb0bcc-0d26-4bce-b479-740b93ffa4eb",
   "metadata": {},
   "source": [
    "## Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4a5d5ec5-d616-4215-92a9-899bb55b017c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def elastic_search_knn(field, vector, course):\n",
    "    knn = {\n",
    "        \"field\": field,\n",
    "        \"query_vector\": vector,\n",
    "        \"k\": 5,\n",
    "        \"num_candidates\": 10000,\n",
    "        \"filter\": {\n",
    "            \"term\": {\n",
    "                \"course\": course\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    search_query = {\n",
    "        \"knn\": knn,\n",
    "        \"_source\": [\"text\", \"section\", \"question\", \"course\", \"id\"]\n",
    "    }\n",
    "\n",
    "    es_results = es_client.search(\n",
    "        index=index_name,\n",
    "        body=search_query\n",
    "    )\n",
    "    \n",
    "    result_docs = []\n",
    "    \n",
    "    for hit in es_results['hits']['hits']:\n",
    "        result_docs.append(hit['_source'])\n",
    "\n",
    "    return result_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "befe92af-5da4-46bc-9e7f-d27e296d9d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def question_vector_knn(q,field='question_text_vector'):\n",
    "    question = q['question']\n",
    "    course= q['course']\n",
    "\n",
    "    embeddings= model.encode(question)\n",
    "    return elastic_search_knn(field=field, \n",
    "                   vector= embeddings,\n",
    "                   course=course)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dd44963f-0fe0-4e0a-89b1-6c027ff0a81e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'question': 'What if I miss a session?',\n",
       "  'course': 'machine-learning-zoomcamp',\n",
       "  'section': 'General course-related questions',\n",
       "  'text': 'Everything is recorded, so you won’t miss anything. You will be able to ask your questions for office hours in advance and we will cover them during the live stream. Also, you can always ask questions in Slack.',\n",
       "  'id': '5170565b'},\n",
       " {'question': 'Is it going to be live? When?',\n",
       "  'course': 'machine-learning-zoomcamp',\n",
       "  'section': 'General course-related questions',\n",
       "  'text': 'The course videos are pre-recorded, you can start watching the course right now.\\nWe will also occasionally have office hours - live sessions where we will answer your questions. The office hours sessions are recorded too.\\nYou can see the office hours as well as the pre-recorded course videos in the course playlist on YouTube.',\n",
       "  'id': '39fda9f0'},\n",
       " {'question': 'The same accuracy on epochs',\n",
       "  'course': 'machine-learning-zoomcamp',\n",
       "  'section': '8. Neural Networks and Deep Learning',\n",
       "  'text': \"Problem description\\nThe accuracy and the loss are both still the same or nearly the same while training.\\nSolution description\\nIn the homework, you should set class_mode='binary' while reading the data.\\nAlso, problem occurs when you choose the wrong optimizer, batch size, or learning rate\\nAdded by Ekaterina Kutovaia\",\n",
       "  'id': '7d11d5ce'},\n",
       " {'question': 'Useful Resource for Missing Data Treatment\\nhttps://www.kaggle.com/code/parulpandey/a-guide-to-handling-missing-values-in-python/notebook',\n",
       "  'course': 'machine-learning-zoomcamp',\n",
       "  'section': '2. Machine Learning for Regression',\n",
       "  'text': '(Hrithik Kumar Advani)',\n",
       "  'id': '81b8e8d0'},\n",
       " {'question': 'Will I get a certificate if I missed the midterm project?',\n",
       "  'course': 'machine-learning-zoomcamp',\n",
       "  'section': 'General course-related questions',\n",
       "  'text': \"Yes, it's possible. See the previous answer.\",\n",
       "  'id': '1d644223'}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_vector_knn(dict(\n",
    "    question='Are sessions recorded if I miss one?',\n",
    "    course='machine-learning-zoomcamp'\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "791aa414-d1e8-49ba-ad05-ceb554535c40",
   "metadata": {},
   "source": [
    "## RAG Flow {from module1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4132ab28-467c-4ea1-b2b2-bb5ff5dfeea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prompt(query, search_results):\n",
    "    prompt_template = \"\"\"\n",
    "You're a course teaching assistant. Answer the QUESTION based on the CONTEXT from the FAQ database.\n",
    "Use only the facts from the CONTEXT when answering the QUESTION.\n",
    "\n",
    "QUESTION: {question}\n",
    "\n",
    "CONTEXT: \n",
    "{context}\n",
    "\"\"\".strip()\n",
    "\n",
    "    context = \"\"\n",
    "    \n",
    "    for doc in search_results:\n",
    "        context = context + f\"section: {doc['section']}\\nquestion: {doc['question']}\\nanswer: {doc['text']}\\n\\n\"\n",
    "    \n",
    "    prompt = prompt_template.format(question=query, context=context).strip()\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9f60498e-3ffe-4cb1-8951-29e00d22cd97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm(prompt, model='gpt-4o'):\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9ea306fa-32eb-4282-b3dc-9a9e8a0097a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# previously: rag(query: str) -> str\n",
    "def rag(query: dict, model='gpt-4o') -> str:\n",
    "    # This gets the search results that will be a context after formualtion\n",
    "    search_results = question_vector_knn(query)\n",
    "    prompt = build_prompt(query['question'], search_results)\n",
    "    answer = llm(prompt, model=model)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "97b35705-a04b-4645-ac21-3f43c81282fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_KEY=\"\"\n",
    "client = OpenAI(api_key=OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c0d03e88-3d93-4039-a6d2-96b7e3afd0b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'Are sessions recorded if I miss one?',\n",
       " 'course': 'machine-learning-zoomcamp',\n",
       " 'document': '5170565b'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ground_truth[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "33526700-3f8c-4b36-9083-5ec0f11e6771",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_answ=rag(ground_truth[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "08c1851a-b573-4b36-994d-f706edf860ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Yes, sessions are recorded if you miss one. You can catch up on the recorded sessions and ask questions in advance for office hours or in Slack.'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_answ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1b1c131a-ab6f-41d0-a071-9298d11b204d",
   "metadata": {},
   "outputs": [],
   "source": [
    "orginal_answ=doc_idx[\"5170565b\"][\"text\"] # the correct answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd45458-5257-4873-a716-363b74933c37",
   "metadata": {},
   "source": [
    "### Cosine Similiarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "065b9728-8fd2-4a3f-a0e3-50c6d0e02d2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.63458365"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_vector=model.encode(rag_answ)\n",
    "original_vector=model.encode(orginal_answ)\n",
    "rag_vector.dot(original_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "19fb91a3-5d3c-4a5f-b359-db75588c9946",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00312308-f321-4d37-b5eb-9377ed5297c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will now do that on the entire dataset\n",
    "# 1. we will go through the entire ground truth dataset questions \n",
    "# 2. generate answer using llm \n",
    "# 3. compute the cos sim between rag_answ & the documents that has the correct answer\n",
    "# will not run this cell as not to pay for open ai & use the one generated from the course \n",
    "# He saved it in a file called results-gpt4o.csv that we will need to load it \n",
    "# if we want to use it \n",
    "# he also generated one wfor gpt-3.5\n",
    "for i,record in enumerate(ground_truth):\n",
    "    # inorder not to recalculate it if there is any error that occurred\n",
    "    if i in answers:\n",
    "        continue \n",
    "    # answer_llm = rag(record)\n",
    "    # indexing the dictionary with the doc_id and getting the document text\n",
    "    id=record['document']\n",
    "    answer_original = doc_idx[id]['text']\n",
    "    answers[i]={\n",
    "        \"answer_llm\":answer_llm,\n",
    "        \"answer_original\":answer_original,\n",
    "        \"document\": id,\n",
    "        'question': rec['question'],\n",
    "        'course': rec['course'],\n",
    "    }"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
